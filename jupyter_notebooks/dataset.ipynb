{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_splits(data, n):\n",
    "\t\n",
    "\ttrain_dataset = []\n",
    "\tvalid_dataset = []\n",
    "\t\n",
    "\tfor sample in data:\n",
    "\t\t\n",
    "\t\tfname = sample[0]\n",
    "\t\tcancer = sample[1]\n",
    "\t\thgd = sample[2]\n",
    "\t\tlgd = sample[3]\n",
    "\t\thyper = sample[4]\n",
    "\t\tnormal = sample[5]\n",
    "\t\tf = sample[6]\n",
    "\t\t\n",
    "\t\trow = [fname, cancer, hgd, lgd, hyper, normal]\n",
    "\t\t\n",
    "\t\tif (f==n):\n",
    "\t\t\t\n",
    "\t\t\tvalid_dataset.append(row)\n",
    "\t\t\n",
    "\t\telse:\n",
    "\t\t\t\n",
    "\t\t\ttrain_dataset.append(row)\n",
    "\t\t\t\n",
    "\ttrain_dataset = np.array(train_dataset, dtype=object)#[:30]\n",
    "\tvalid_dataset = np.array(valid_dataset, dtype=object)#[:30]\n",
    "\t\n",
    "\t#train_dataset = np.append(train_dataset, cad_data, axis=0)\n",
    "\n",
    "\treturn train_dataset, valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'sampler': <__main__.Balanced_Multimodal object at 0x7f1ad4d4e4c0>}\n",
      "<__main__.Dataset_bag object at 0x7f1ad4a3c5b0>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f1ad2cec8e0>\n"
     ]
    }
   ],
   "source": [
    "#parameters bag\n",
    "\n",
    "batch_size_bag = 16\n",
    "\n",
    "datadir = Path(thispath.parent / \"data\")\n",
    "train_dataset = pd.read_csv(Path(datadir / \"labels.csv\"), header=0).values\n",
    "\"\"\"\n",
    "sampler = ImbalancedDatasetSampler_multilabel\n",
    "params_train_bag = {'batch_size': batch_size_bag,\n",
    "\t\t'sampler': sampler(train_dataset)}\n",
    "\t\t#'shuffle': True}\n",
    "\"\"\"\n",
    "#\"\"\"\n",
    "sampler = Balanced_Multimodal\n",
    "params_train_bag = {'batch_size': batch_size_bag,\n",
    "\t\t#'sampler': sampler(train_dataset,alpha=0.25)}\n",
    "\t\t'shuffle': True}\n",
    "#\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "sampler = Balanced_Multimodal\n",
    "params_bag_train = {'batch_size': batch_size_bag,\n",
    "\t\t'sampler': sampler(train_dataset,alpha=0.5)}\n",
    "\t\t#'shuffle': True}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "params_bag_test = {'batch_size': batch_size_bag,\n",
    "\t\t#'sampler': sampler(train_dataset)\n",
    "\t  'shuffle': True}\n",
    "\n",
    "params_bag_train_queue = {'batch_size': int(batch_size_bag*2),\n",
    "\t\t'sampler': sampler(train_dataset,alpha=0.25)}\n",
    "\t  #'shuffle': True}\n",
    "print(params_bag_train_queue)\n",
    "params_bag_test_queue = {'batch_size': int(batch_size_bag*2),\n",
    "\t\t#'sampler': sampler(train_dataset)\n",
    "\t  'shuffle': True}\n",
    "\n",
    "training_set_bag = Dataset_bag(train_dataset[:,0], train_dataset[:,1:])\n",
    "print(training_set_bag)\n",
    "training_generator_bag = DataLoader(training_set_bag, **params_train_bag)\n",
    "print(training_generator_bag)\n",
    "\n",
    "#validation_set_bag = Dataset_bag(valid_dataset[:,0], valid_dataset[:,1:])\n",
    "#validation_generator_bag = data.DataLoader(validation_set_bag, **params_bag_test)\n",
    "\n",
    "training_set_bag = Dataset_bag(train_dataset[:,0], train_dataset[:,1:])\n",
    "training_generator_bag_queue = DataLoader(training_set_bag, **params_bag_train_queue)\n",
    "\n",
    "#validation_set_bag = Dataset_bag(valid_dataset[:,0], valid_dataset[:,1:])\n",
    "#validation_generator_bag_queue = data.DataLoader(validation_set_bag, **params_bag_test_queue)\n",
    "\n",
    "#params patches generated\n",
    "\n",
    "# Find total parameters and trainable parameters\n",
    "# total_params = sum(p.numel() for p in encoder.parameters())\n",
    "# print(f'{total_params:,} total parameters.')\n",
    "\n",
    "# total_trainable_params = sum(\n",
    "# \tp.numel() for p in encoder.parameters() if p.requires_grad)\n",
    "# print(f'{total_trainable_params:,} training parameters.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "libgomp-f7e03b3e.so.1.0.0: cannot open shared object file: No such file or directory\n___________________________________________________________________________\nContents of /home/lluis/.local/lib/python3.8/site-packages/sklearn/__check_build:\nsetup.py                  __init__.py               __pycache__\n_check_build.cpython-38-x86_64-linux-gnu.so\n___________________________________________________________________________\nIt seems that scikit-learn has not been built correctly.\n\nIf you have installed scikit-learn from source, please do not forget\nto build the package before using it: run `python setup.py install` or\n`make` in the source directory.\n\nIf you have used an installer, please check that it is suited for your\nPython version, your operating system and your platform.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/__check_build/__init__.py:44\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_check_build\u001b[39;00m \u001b[39mimport\u001b[39;00m check_build  \u001b[39m# noqa\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mImportError\u001b[0m: libgomp-f7e03b3e.so.1.0.0: cannot open shared object file: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m KFold\n\u001b[1;32m      4\u001b[0m kf \u001b[39m=\u001b[39m KFold(n_splits\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m kf\u001b[39m.\u001b[39msplit(train_dataset):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/__init__.py:81\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[39m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     \u001b[39m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[39m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[1;32m     79\u001b[0m     \u001b[39m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _distributor_init  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m __check_build  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m clone\n\u001b[1;32m     83\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_show_versions\u001b[39;00m \u001b[39mimport\u001b[39;00m show_versions\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/__check_build/__init__.py:46\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_check_build\u001b[39;00m \u001b[39mimport\u001b[39;00m check_build  \u001b[39m# noqa\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m---> 46\u001b[0m     raise_build_error(e)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/__check_build/__init__.py:31\u001b[0m, in \u001b[0;36mraise_build_error\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m             dir_content\u001b[39m.\u001b[39mappend(filename \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m\"\"\"\u001b[39m\u001b[39m%s\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39m___________________________________________________________________________\u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[39mContents of \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m:\u001b[39m\n\u001b[1;32m     34\u001b[0m \u001b[39m%s\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39m___________________________________________________________________________\u001b[39m\n\u001b[1;32m     36\u001b[0m \u001b[39mIt seems that scikit-learn has not been built correctly.\u001b[39m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[39mIf you have installed scikit-learn from source, please do not forget\u001b[39m\n\u001b[1;32m     39\u001b[0m \u001b[39mto build the package before using it: run `python setup.py install` or\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[39m`make` in the source directory.\u001b[39m\n\u001b[1;32m     41\u001b[0m \u001b[39m%s\u001b[39;00m\u001b[39m\"\"\"\u001b[39m \u001b[39m%\u001b[39m (e, local_dir, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(dir_content)\u001b[39m.\u001b[39mstrip(), msg))\n",
      "\u001b[0;31mImportError\u001b[0m: libgomp-f7e03b3e.so.1.0.0: cannot open shared object file: No such file or directory\n___________________________________________________________________________\nContents of /home/lluis/.local/lib/python3.8/site-packages/sklearn/__check_build:\nsetup.py                  __init__.py               __pycache__\n_check_build.cpython-38-x86_64-linux-gnu.so\n___________________________________________________________________________\nIt seems that scikit-learn has not been built correctly.\n\nIf you have installed scikit-learn from source, please do not forget\nto build the package before using it: run `python setup.py install` or\n`make` in the source directory.\n\nIf you have used an installer, please check that it is suited for your\nPython version, your operating system and your platform."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=2)\n",
    "for train, test in kf.split(train_dataset):\n",
    "    print(\"%s %s\" % (train, test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lung_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6158f16043df0ed03e0f0bf66374ee44ce8098f515735805958080d32960790b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
