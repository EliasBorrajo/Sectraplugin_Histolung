{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class ModelOption():\n",
    "    def __init__(self, model_name: str,\n",
    "                 num_classes: int,\n",
    "                 freeze=False,\n",
    "                 num_freezed_layers=0,\n",
    "                 seg_mask=False,\n",
    "                 dropout=0.0):\n",
    "\n",
    "        self.model_name = model_name\n",
    "        self.num_classes = num_classes\n",
    "        self.freeze = freeze\n",
    "        self.num_freezed_layers = num_freezed_layers\n",
    "        self.seg_mask = seg_mask\n",
    "        self.dropout = dropout\n",
    "\n",
    "        if self.model_name.lower() == \"resnet\":\n",
    "            \"\"\" ResNet50 \"\"\"\n",
    "            self.net = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "            if self.seg_mask:\n",
    "                #   Modifying the input layer to receive 4-channel image instead of 3-channel image,\n",
    "                #   We keep the pretrained weights for the RGB channels of the images\n",
    "                weight1 = self.net.conv1.weight.clone()\n",
    "                new_first_layer = nn.Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3),\n",
    "                                            bias=False).requires_grad_()\n",
    "                new_first_layer.weight[:, :3, :, :].data[...] = Variable(weight1, requires_grad=True)\n",
    "                self.net.conv1 = new_first_layer\n",
    "\n",
    "            if self.freeze:\n",
    "                # Freezing the number of layers\n",
    "                # ResNet has two named layers in position 2 and 3 named relu and maxpool\n",
    "                # that do not have any learnable parameters, therefore if the user wants to\n",
    "                # freeze more than 2 layers we offset the num_freezed_layers with two\n",
    "                if self.num_freezed_layers > 2:\n",
    "                    self.net = self.set_parameter_requires_grad(self.net, self.num_freezed_layers + 2)\n",
    "                else:\n",
    "                    self.net = self.set_parameter_requires_grad(self.net, self.num_freezed_layers)\n",
    "\n",
    "            input_features = self.net.fc.in_features  # 2048\n",
    "            self.net.fc = nn.Sequential(nn.Dropout(p=self.dropout),\n",
    "                                nn.Linear(input_features, input_features // 4),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Dropout(p=self.dropout),\n",
    "                                nn.Linear(input_features // 4, input_features // 8),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Dropout(p=self.dropout),\n",
    "                                nn.Linear(input_features // 8, self.num_classes))\n",
    "            \n",
    "            self.resize_param = 224\n",
    "\n",
    "        elif self.model_name.lower() == \"convnext\":\n",
    "            \"\"\" ConvNeXt small \"\"\"\n",
    "            self.net = models.convnext_small(weights='DEFAULT')\n",
    "\n",
    "            if self.seg_mask:\n",
    "                #   Modifying the input layer to receive 4-channel image instead of 3-channel image,\n",
    "                #   We keep the pretrained weights for the RGB channels of the images\n",
    "                weight1 = self.net.features[0][0].weight.clone()\n",
    "                bias1 = self.net.features[0][0].bias.clone()\n",
    "                new_first_layer = nn.Conv2d(4, 96, kernel_size=(4, 4), stride=(4, 4), padding=(0, 0),\n",
    "                                            bias=True).requires_grad_()\n",
    "                new_first_layer.weight[:, :3, :, :].data[...] = Variable(weight1, requires_grad=True)\n",
    "                new_first_layer.bias.data[...] = Variable(bias1, requires_grad=True)\n",
    "                self.net.features[0][0] = new_first_layer\n",
    "                \n",
    "            if self.freeze:\n",
    "                # Freezing the number of layers\n",
    "                self.net.features = self.set_parameter_requires_grad(self.net.features, self.num_freezed_layers)\n",
    "\n",
    "            input_features = self.net.classifier[2].in_features  # 768\n",
    "            self.net.classifier[2] = nn.Sequential(nn.Dropout(p=self.dropout),\n",
    "                                            nn.Linear(input_features, input_features // 2),\n",
    "                                            nn.ReLU(inplace=True),\n",
    "                                            nn.Dropout(p=self.dropout),\n",
    "                                            nn.Linear(input_features // 2, input_features // 4),\n",
    "                                            nn.ReLU(inplace=True),\n",
    "                                            nn.Dropout(p=self.dropout),\n",
    "                                            nn.Linear(input_features // 4, self.num_classes))\n",
    "            \n",
    "            self.resize_param = 224\n",
    "\n",
    "        elif self.model_name.lower() == \"swin\":\n",
    "            \"\"\" Swin Transformer V2 -T \"\"\"\n",
    "            self.net = models.swin_v2_t(weights=models.Swin_V2_T_Weights.DEFAULT)\n",
    "\n",
    "            if self.seg_mask:\n",
    "                #   Modifying the input layer to receive 4-channel image instead of 3-channel image,\n",
    "                #   We keep the pretrained weights for the RGB channels of the images\n",
    "                weight1 = self.net.features[0][0].weight.clone()\n",
    "                bias1 = self.net.features[0][0].bias.clone()\n",
    "                new_first_layer = nn.Conv2d(4, 96, kernel_size=(4, 4), stride=(4, 4), padding=(0, 0),\n",
    "                                            bias=True).requires_grad_()\n",
    "                new_first_layer.weight[:, :3, :, :].data[...] = Variable(weight1, requires_grad=True)\n",
    "                new_first_layer.bias.data[...] = Variable(bias1, requires_grad=True)\n",
    "                self.net.features[0][0] = new_first_layer\n",
    "\n",
    "            if self.freeze:\n",
    "                # Freezing the number of layers\n",
    "                self.net.features = self.set_parameter_requires_grad(self.net.features, self.num_freezed_layers)\n",
    "\n",
    "            input_features = self.net.head.in_features  # 768\n",
    "            self.net.head = nn.Sequential(nn.Dropout(p=self.dropout),\n",
    "                                    nn.Linear(input_features, input_features // 2),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Dropout(p=self.dropout),\n",
    "                                    nn.Linear(input_features // 2, input_features // 4),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Dropout(p=self.dropout),\n",
    "                                    nn.Linear(input_features // 4, self.num_classes))\n",
    "            \n",
    "            self.resize_param = 224\n",
    "\n",
    "        elif self.model_name.lower() == \"efficient\":\n",
    "            \"\"\" EfficientNet b0 \"\"\"\n",
    "            self.net = models.efficientnet_b0(weights='DEFAULT')\n",
    "\n",
    "            if self.seg_mask:\n",
    "                #   Modifying the input layer to receive 4-channel image instead of 3-channel image,\n",
    "                #   We keep the pretrained weights for the RGB channels of the images\n",
    "                weight1 = self.net.features[0][0].weight.clone()\n",
    "                new_first_layer = nn.Conv2d(4, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1),\n",
    "                                            bias=False).requires_grad_()\n",
    "                new_first_layer.weight[:, :3, :, :].data[...] = Variable(weight1, requires_grad=True)\n",
    "                self.net.features[0][0] = new_first_layer\n",
    "\n",
    "            if self.freeze:\n",
    "                # Freezing the number of layers\n",
    "                self.net.features = self.set_parameter_requires_grad(self.net.features, self.num_freezed_layers, feature_layers=9)\n",
    "\n",
    "            input_features = self.net.classifier[1].in_features  # 1200\n",
    "            self.net.classifier = nn.Sequential(nn.Dropout(p=self.dropout),\n",
    "                                        nn.Linear(input_features, input_features // 2),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.Dropout(p=self.dropout),\n",
    "                                        nn.Linear(input_features // 2, input_features // 4),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.Dropout(p=self.dropout),\n",
    "                                        nn.Linear(input_features // 4, self.num_classes))\n",
    "            \n",
    "            self.resize_param = 224\n",
    "\n",
    "        else:\n",
    "            print(\"Invalid model name, MODEL NOT LOAD\")\n",
    "            TypeError(\"Valid model names are 'resnet', 'convnext', 'swim' or 'efficient'\")\n",
    "            exit()\n",
    "\n",
    "    def set_parameter_requires_grad(model, number_frozen_layers, feature_layers=8):\n",
    "        for k, child in enumerate(model.named_children()):\n",
    "            if k == number_frozen_layers or k == feature_layers:\n",
    "                break\n",
    "            for param in child[1].parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With configuration file in: /home/lluis/histo_lung/training/config.yml\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "thispath = Path.cwd().resolve()\n",
    "\n",
    "# read the configuration file\n",
    "config_path = str(thispath.parent / \"training\" / 'config.yml')\n",
    "print(f\"With configuration file in: {config_path}\")\n",
    "with open(config_path, \"r\") as ymlfile:\n",
    "    cfg = yaml.safe_load(ymlfile)\n",
    "# use the configuration for the network\n",
    "model_arguments = cfg['model']\n",
    "\n",
    "model = ModelOption(model_arguments['model_name'],\n",
    "                                     model_arguments['num_classes'],\n",
    "                                     freeze=model_arguments['freeze_weights'],\n",
    "                                     num_freezed_layers=model_arguments['num_frozen_layers'],\n",
    "                                     seg_mask=cfg['dataset']['use_masks'],\n",
    "                                     dropout=model_arguments['dropout'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224\n",
      "ResNet(\n",
      "  (conv1): Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Dropout(p=0.2, inplace=False)\n",
      "    (7): Linear(in_features=256, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model.resize_param)\n",
    "print(model.net)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lung_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6158f16043df0ed03e0f0bf66374ee44ce8098f515735805958080d32960790b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
