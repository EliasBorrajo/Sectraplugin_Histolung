{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class ModelOption():\n",
    "    def __init__(self, model_name: str,\n",
    "                 num_classes: int,\n",
    "                 freeze=False,\n",
    "                 num_freezed_layers=0,\n",
    "                 seg_mask=False,\n",
    "                 dropout=0.0):\n",
    "\n",
    "        self.model_name = model_name\n",
    "        self.num_classes = num_classes\n",
    "        self.freeze = freeze\n",
    "        self.num_freezed_layers = num_freezed_layers\n",
    "        self.seg_mask = seg_mask\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def set_parameter_requires_grad(model, number_frozen_layers, feature_layers=8):\n",
    "        for k, child in enumerate(model.named_children()):\n",
    "            if k == number_frozen_layers or k == feature_layers:\n",
    "                break\n",
    "            for param in child[1].parameters():\n",
    "                param.requires_grad = False\n",
    "        return model\n",
    "    \n",
    "    def __call__(self, net, resize_param):\n",
    "\n",
    "        if self.model_name.lower() == \"resnet\":\n",
    "            \"\"\" ResNet50 \"\"\"\n",
    "            net = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "            if self.seg_mask:\n",
    "                #   Modifying the input layer to receive 4-channel image instead of 3-channel image,\n",
    "                #   We keep the pretrained weights for the RGB channels of the images\n",
    "                weight1 = net.conv1.weight.clone()\n",
    "                new_first_layer = nn.Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3),\n",
    "                                            bias=False).requires_grad_()\n",
    "                new_first_layer.weight[:, :3, :, :].data[...] = Variable(weight1, requires_grad=True)\n",
    "                net.conv1 = new_first_layer\n",
    "\n",
    "            if self.freeze:\n",
    "                # Freezing the number of layers\n",
    "                # ResNet has two named layers in position 2 and 3 named relu and maxpool\n",
    "                # that do not have any learnable parameters, therefore if the user wants to\n",
    "                # freeze more than 2 layers we offset the num_freezed_layers with two\n",
    "                if self.num_freezed_layers > 2:\n",
    "                    net = self.set_parameter_requires_grad(net, self.num_freezed_layers + 2)\n",
    "                else:\n",
    "                    net = self.set_parameter_requires_grad(net, self.num_freezed_layers)\n",
    "\n",
    "            input_features = net.fc.in_features  # 2048\n",
    "            net.fc = nn.Sequential(nn.Dropout(p=self.dropout),\n",
    "                                nn.Linear(input_features, input_features // 4),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Dropout(p=self.dropout),\n",
    "                                nn.Linear(input_features // 4, input_features // 8),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Dropout(p=self.dropout),\n",
    "                                nn.Linear(input_features // 8, self.num_classes))\n",
    "            resize_param = 224\n",
    "\n",
    "        elif self.model_name.lower() == \"convnext\":\n",
    "            \"\"\" ConvNeXt small \"\"\"\n",
    "            net = models.convnext_small(weights='DEFAULT')\n",
    "            if self.seg_mask:\n",
    "                #   Modifying the input layer to receive 4-channel image instead of 3-channel image,\n",
    "                #   We keep the pretrained weights for the RGB channels of the images\n",
    "                weight1 = net.features[0][0].weight.clone()\n",
    "                bias1 = net.features[0][0].bias.clone()\n",
    "                new_first_layer = nn.Conv2d(4, 96, kernel_size=(4, 4), stride=(4, 4), padding=(0, 0),\n",
    "                                            bias=True).requires_grad_()\n",
    "                new_first_layer.weight[:, :3, :, :].data[...] = Variable(weight1, requires_grad=True)\n",
    "                new_first_layer.bias.data[...] = Variable(bias1, requires_grad=True)\n",
    "                net.features[0][0] = new_first_layer\n",
    "            if self.freeze:\n",
    "                # Freezing the number of layers\n",
    "                net.features = self.set_parameter_requires_grad(net.features, self.num_freezed_layers)\n",
    "            input_features = net.classifier[2].in_features  # 768\n",
    "            net.classifier[2] = nn.Sequential(nn.Dropout(p=self.dropout),\n",
    "                                            nn.Linear(input_features, input_features // 2),\n",
    "                                            nn.ReLU(inplace=True),\n",
    "                                            nn.Dropout(p=self.dropout),\n",
    "                                            nn.Linear(input_features // 2, input_features // 4),\n",
    "                                            nn.ReLU(inplace=True),\n",
    "                                            nn.Dropout(p=self.dropout),\n",
    "                                            nn.Linear(input_features // 4, self.num_classes))\n",
    "            resize_param = 224\n",
    "\n",
    "        elif self.model_name.lower() == \"swin\":\n",
    "            \"\"\" Swin Transformer V2 -T \"\"\"\n",
    "            net = models.swin_v2_t(weights=models.Swin_V2_T_Weights.DEFAULT)\n",
    "            if self.seg_mask:\n",
    "                #   Modifying the input layer to receive 4-channel image instead of 3-channel image,\n",
    "                #   We keep the pretrained weights for the RGB channels of the images\n",
    "                weight1 = net.features[0][0].weight.clone()\n",
    "                bias1 = net.features[0][0].bias.clone()\n",
    "                new_first_layer = nn.Conv2d(4, 96, kernel_size=(4, 4), stride=(4, 4), padding=(0, 0),\n",
    "                                            bias=True).requires_grad_()\n",
    "                new_first_layer.weight[:, :3, :, :].data[...] = Variable(weight1, requires_grad=True)\n",
    "                new_first_layer.bias.data[...] = Variable(bias1, requires_grad=True)\n",
    "                net.features[0][0] = new_first_layer\n",
    "            if self.freeze:\n",
    "                # Freezing the number of layers\n",
    "                net.features = self.set_parameter_requires_grad(net.features, self.num_freezed_layers)\n",
    "            input_features = net.head.in_features  # 768\n",
    "            net.head = nn.Sequential(nn.Dropout(p=self.dropout),\n",
    "                                    nn.Linear(input_features, input_features // 2),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Dropout(p=self.dropout),\n",
    "                                    nn.Linear(input_features // 2, input_features // 4),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Dropout(p=self.dropout),\n",
    "                                    nn.Linear(input_features // 4, self.num_classes))\n",
    "            resize_param = 224\n",
    "\n",
    "        elif self.model_name.lower() == \"efficient\":\n",
    "            net = models.efficientnet_b0(weights='DEFAULT')\n",
    "            if self.seg_mask:\n",
    "                #   Modifying the input layer to receive 4-channel image instead of 3-channel image,\n",
    "                #   We keep the pretrained weights for the RGB channels of the images\n",
    "                weight1 = net.features[0][0].weight.clone()\n",
    "                new_first_layer = nn.Conv2d(4, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1),\n",
    "                                            bias=False).requires_grad_()\n",
    "                new_first_layer.weight[:, :3, :, :].data[...] = Variable(weight1, requires_grad=True)\n",
    "                net.features[0][0] = new_first_layer\n",
    "            if self.freeze:\n",
    "                # Freezing the number of layers\n",
    "                net.features = self.set_parameter_requires_grad(net.features, self.num_freezed_layers, feature_layers=9)\n",
    "            input_features = net.classifier[1].in_features  # 1200\n",
    "            net.classifier = nn.Sequential(nn.Dropout(p=self.dropout),\n",
    "                                        nn.Linear(input_features, input_features // 2),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.Dropout(p=self.dropout),\n",
    "                                        nn.Linear(input_features // 2, input_features // 4),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.Dropout(p=self.dropout),\n",
    "                                        nn.Linear(input_features // 4, self.num_classes))\n",
    "            resize_param = 224\n",
    "\n",
    "        else:\n",
    "            print(\"Invalid model name, exiting...\")\n",
    "            TypeError(\"Valid model names are 'resnet', 'convnext', 'swim' or 'efficient'\")\n",
    "            exit()\n",
    "\n",
    "        self.net = net\n",
    "        self.resize_param = resize_param\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelOption()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lung_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6158f16043df0ed03e0f0bf66374ee44ce8098f515735805958080d32960790b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
