{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from natsort import natsorted\n",
    "import yaml\n",
    "from easydict import EasyDict as edict\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspng\n",
    "\n",
    "# Functions\n",
    "def yaml_load(fileName):\n",
    "    dict_config = None\n",
    "    with open(fileName, 'r') as ymlfile:\n",
    "        dict_config = edict(yaml.safe_load(ymlfile))\n",
    "\n",
    "    return dict_config\n",
    "\n",
    "\n",
    "class Dataset_instance(Dataset):\n",
    "\n",
    "    def __init__(self, wsi_path_patches, transform=None, preprocess=None):\n",
    "\n",
    "        self.wsi_path_patches = wsi_path_patches\n",
    "        self.transform = transform\n",
    "        self.preprocess = preprocess\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.wsi_path_patches)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # Load the patch image saved as png (key)\n",
    "        with open(self.wsi_path_patches[index][0], 'rb') as fin:\n",
    "            key =  pyspng.load(fin.read())\n",
    "\n",
    "        if self.transform:\n",
    "            query = self.transform(image=key)['image']\n",
    "        else:\n",
    "            query = key\n",
    "\n",
    "        if self.preprocess:\n",
    "            query = self.preprocess(query).type(torch.FloatTensor)\n",
    "            key = self.preprocess(key).type(torch.FloatTensor)\n",
    "        \n",
    "        return key, query\n",
    "\n",
    "\n",
    "class ModelOption():\n",
    "    def __init__(self, model_name: str,\n",
    "                 num_classes: int,\n",
    "                 freeze=False,\n",
    "                 num_freezed_layers=0,\n",
    "                 dropout=0.0, \n",
    "                 embedding_bool=False):\n",
    "\n",
    "        self.model_name = model_name\n",
    "        self.num_classes = num_classes\n",
    "        self.freeze = freeze\n",
    "        self.num_freezed_layers = num_freezed_layers\n",
    "        self.dropout = dropout\n",
    "        self.embedding_bool = embedding_bool\n",
    "\n",
    "        if self.model_name.lower() == \"resnet50\":\n",
    "            \"\"\" ResNet50 \"\"\"\n",
    "            self.net = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "            if self.freeze:\n",
    "                # Freezing the number of layers\n",
    "                # ResNet has two named layers in position 2 and 3 named relu and maxpool\n",
    "                # that do not have any learnable parameters, therefore if the user wants to\n",
    "                # freeze more than 2 layers we offset the num_freezed_layers with two\n",
    "                if self.num_freezed_layers > 2:\n",
    "                    self.net = self.set_parameter_requires_grad(self.net,\n",
    "                                                                self.num_freezed_layers + 2)\n",
    "                else:\n",
    "                    self.net = self.set_parameter_requires_grad(self.net,\n",
    "                                                                \n",
    "                                                                self.num_freezed_layers)\n",
    "\n",
    "            self.input_features = self.net.fc.in_features  # 2048\n",
    "            \n",
    "            # self.net.fc = nn.Sequential(nn.Dropout(p=self.dropout),\n",
    "            #                             nn.Linear(input_features,\n",
    "            #                                       input_features // 4),\n",
    "            #                             nn.ReLU(inplace=True),\n",
    "            #                             nn.Dropout(p=self.dropout),\n",
    "            #                             nn.Linear(input_features // 4,\n",
    "            #                                      input_features // 8),\n",
    "            #                             nn.ReLU(inplace=True),\n",
    "            #                             nn.Dropout(p=self.dropout),\n",
    "            #                             nn.Linear(input_features // 8,\n",
    "            #                                      self.num_classes))\n",
    "\n",
    "            self.resize_param = 224\n",
    "\n",
    "        elif self.model_name.lower() == \"convnext\":\n",
    "            \"\"\" ConvNeXt small \"\"\"\n",
    "            self.net = models.convnext_small(weights='DEFAULT')\n",
    "\n",
    "            if self.freeze:\n",
    "                # Freezing the number of layers\n",
    "                self.net.features = self.set_parameter_requires_grad(self.net.features,\n",
    "                                                                     self.num_freezed_layers)\n",
    "\n",
    "            input_features = self.net.classifier[2].in_features  # 768\n",
    "            self.net.classifier[2] = nn.Sequential(nn.Dropout(p=self.dropout),\n",
    "                                                   nn.Linear(input_features,\n",
    "                                                             input_features // 2),\n",
    "                                                   nn.ReLU(inplace=True),\n",
    "                                                   nn.Dropout(p=self.dropout),\n",
    "                                                   nn.Linear(input_features // 2,\n",
    "                                                             input_features // 4),\n",
    "                                                   nn.ReLU(inplace=True),\n",
    "                                                   nn.Dropout(p=self.dropout),\n",
    "                                                   nn.Linear(input_features // 4,\n",
    "                                                             self.num_classes))\n",
    "\n",
    "            self.resize_param = 224\n",
    "\n",
    "        elif self.model_name.lower() == \"swin\":\n",
    "            \"\"\" Swin Transformer V2 -T \"\"\"\n",
    "            self.net = models.swin_v2_t(weights=models.Swin_V2_T_Weights.DEFAULT)\n",
    "\n",
    "            if self.freeze:\n",
    "                # Freezing the number of layers\n",
    "                self.net.features = self.set_parameter_requires_grad(self.net.features,\n",
    "                                                                     self.num_freezed_layers)\n",
    "\n",
    "            input_features = self.net.head.in_features  # 768\n",
    "            self.net.head = nn.Sequential(nn.Dropout(p=self.dropout),\n",
    "                                          nn.Linear(input_features,\n",
    "                                                    input_features // 2),\n",
    "                                          nn.ReLU(inplace=True),\n",
    "                                          nn.Dropout(p=self.dropout),\n",
    "                                          nn.Linear(input_features // 2,\n",
    "                                                    input_features // 4),\n",
    "                                          nn.ReLU(inplace=True),\n",
    "                                          nn.Dropout(p=self.dropout),\n",
    "                                          nn.Linear(input_features // 4,\n",
    "                                                    self.num_classes))\n",
    "\n",
    "            self.resize_param = 224\n",
    "\n",
    "        elif self.model_name.lower() == \"efficient\":\n",
    "            \"\"\" EfficientNet b0 \"\"\"\n",
    "            self.net = models.efficientnet_b0(weights='DEFAULT')\n",
    "\n",
    "            if self.freeze:\n",
    "                # Freezing the number of layers\n",
    "                self.net.features = self.set_parameter_requires_grad(self.net.features,\n",
    "                                                                     self.num_freezed_layers,\n",
    "                                                                     feature_layers=9)\n",
    "\n",
    "            input_features = self.net.classifier[1].in_features  # 1200\n",
    "            self.net.classifier = nn.Sequential(nn.Dropout(p=self.dropout),\n",
    "                                                nn.Linear(input_features,\n",
    "                                                          input_features // 2),\n",
    "                                                nn.ReLU(inplace=True),\n",
    "                                                nn.Dropout(p=self.dropout),\n",
    "                                                nn.Linear(input_features // 2,\n",
    "                                                          input_features // 4),\n",
    "                                                nn.ReLU(inplace=True),\n",
    "                                                nn.Dropout(p=self.dropout),\n",
    "                                                nn.Linear(input_features // 4,\n",
    "                                                          self.num_classes))\n",
    "\n",
    "            self.resize_param = 224\n",
    "\n",
    "        else:\n",
    "            print(\"Invalid model name, MODEL NOT LOAD\")\n",
    "            TypeError(\"Valid model names are 'resnet', 'convnext', 'swim' or 'efficient'\")\n",
    "            exit()\n",
    "\n",
    "    def set_parameter_requires_grad(model, number_frozen_layers, feature_layers=8):\n",
    "        for k, child in enumerate(model.named_children()):\n",
    "            if k == number_frozen_layers or k == feature_layers:\n",
    "                break\n",
    "            for param in child[1].parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        return model\n",
    "    \n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, model, dim):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear modules and assign them as\n",
    "        member variables.\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.model = model\n",
    "        self.fc_input_features = self.model.input_features\n",
    "        self.num_classes = self.model.num_classes\n",
    "        self.dim = dim\n",
    "        self.net = self.model.net\n",
    "\n",
    "        self.conv_layers = torch.nn.Sequential(*list(self.net.children())[:-1])\n",
    "\n",
    "        if (torch.cuda.device_count()>1):\n",
    "            self.conv_layers = torch.nn.DataParallel(self.conv_layers)\n",
    "\n",
    "        if self.model.embedding_bool:\n",
    "\n",
    "            if ('resnet34' in self.model.model_name):\n",
    "                self.E = self.dim\n",
    "                self.L = self.E\n",
    "                self.D = 64\n",
    "                self.K = self.num_classes\n",
    "\n",
    "            elif ('resnet50' in self.model.model_name):\n",
    "                self.E = self.dim\n",
    "                self.L = self.E\n",
    "                self.D = 128\n",
    "                self.K = self.num_classes\n",
    "\n",
    "            elif ('resnet152' in self.model.model_name):\n",
    "                self.E = self.dim\n",
    "                self.L = self.E\n",
    "                self.D = 128\n",
    "                self.K = self.num_classes\n",
    "\n",
    "            self.embedding = torch.nn.Linear(in_features=self.fc_input_features, out_features=self.E)\n",
    "            self.post_embedding = torch.nn.Linear(in_features=self.E, out_features=self.E)\n",
    "\n",
    "        self.prelu = torch.nn.PReLU(num_parameters=1, init=0.25) \n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Tensor of input data and we must return\n",
    "        a Tensor of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Tensors.\n",
    "        \"\"\"\n",
    "        #if used attention pooling\n",
    "        A = None\n",
    "        #m = torch.nn.Softmax(dim=1)\n",
    "        dropout = torch.nn.Dropout(p=0.2)\n",
    "        relu = torch.nn.ReLU()\n",
    "        tanh = torch.nn.Tanh()\n",
    "\n",
    "        if x is not None:\n",
    "            #print(x.shape)\n",
    "            conv_layers_out = self.conv_layers(x)\n",
    "            #print(x.shape)\n",
    "\n",
    "            conv_layers_out = conv_layers_out.view(-1, self.fc_input_features)\n",
    "\n",
    "        if self.model.embedding_bool:\n",
    "            #embedding_layer = self.relu(conv_layers_out)\n",
    "            embedding_layer = self.embedding(conv_layers_out)\n",
    "            embedding_layer = self.relu(embedding_layer)\n",
    "            embedding_layer = self.post_embedding(embedding_layer)\n",
    "\n",
    "            features_to_return = embedding_layer\n",
    "\n",
    "        else:\n",
    "            features_to_return = conv_layers_out\n",
    "\n",
    "        norm = torch.norm(features_to_return, p='fro', dim=1, keepdim=True)\n",
    "\n",
    "        #normalized_array = features_to_return #/ norm\n",
    "        #normalized_array = torch.nn.functional.normalize(features_to_return, dim=1)\n",
    "        #normalized_array = torch.norm(features_to_return, p='fro', dim=1, keepdim=True)\n",
    "        normalized_array = features_to_return \n",
    "\n",
    "        return normalized_array\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lluis/miniconda3/envs/hlung/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded encoder using as backbone resnet50 with a best loss of 7.036789032876164 at Epoch 19\n",
      "0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting patches to check model: 100%|██████████| 2/2 [00:00<00:00, 190.17it/s]\n"
     ]
    }
   ],
   "source": [
    "thispath = Path.cwd().resolve()\n",
    "\n",
    "datadir = Path(thispath.parent / \"data\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load PyTorch model\n",
    "experiment_name = \"MoCo_try_Adam\"\n",
    "\n",
    "modeldir = Path(thispath.parent / \"trained_models\" / experiment_name)\n",
    "\n",
    "cfg = yaml_load(modeldir / f\"config_{experiment_name}.yml\")\n",
    "\n",
    "model = ModelOption(cfg.model.model_name,\n",
    "                cfg.model.num_classes,\n",
    "                freeze=cfg.model.freeze_weights,\n",
    "                num_freezed_layers=cfg.model.num_frozen_layers,\n",
    "                dropout=cfg.model.dropout,\n",
    "                embedding_bool=cfg.model.embedding_bool\n",
    "                )    \n",
    "\n",
    "# Encoder and momentum encoder\n",
    "moco_dim = cfg.training.moco_dim\n",
    "\n",
    "encoder = Encoder(model, dim=moco_dim).to(device)\n",
    "\n",
    "optimizer = getattr(torch.optim, cfg.training.optimizer)\n",
    "optimizer = optimizer(encoder.parameters(), **cfg.training.optimizer_args)\n",
    "\n",
    "# checkpoint = torch.load(modeldir / cfg.dataset.magnification / cfg.model.model_name / f\"{experiment_name}.pt\")\n",
    "checkpoint = torch.load(modeldir / cfg.dataset.magnification / cfg.model.model_name / \"MoCo.pt\")\n",
    "encoder.load_state_dict(checkpoint[\"encoder_state_dict\"])\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "loss = checkpoint[\"loss\"]\n",
    "epoch = checkpoint[\"epoch\"] + 1\n",
    "\n",
    "print(f\"Loaded encoder using as backbone {cfg.model.model_name} with a best loss of {loss} at Epoch {epoch}\")\n",
    "print(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "# Load patches\n",
    "pyhistdir = Path(datadir / \"Mask_PyHIST_v2\")\n",
    "\n",
    "selected_wsi = [\"000030303300314205\", \"000030494900323685\"]\n",
    "\n",
    "dataset_path = natsorted([i for i in pyhistdir.rglob(\"*_densely_filtered_paths.csv\") if selected_wsi[0] in str(i) or selected_wsi[1] in str(i)])\n",
    "\n",
    "number_patches = 0\n",
    "path_patches = []\n",
    "for wsi_patches in tqdm(dataset_path, desc=\"Selecting patches to check model\"):\n",
    "\n",
    "    csv_instances = pd.read_csv(wsi_patches).to_numpy()\n",
    "    \n",
    "    path_patches.extend(csv_instances)\n",
    "\n",
    "selected_patches = [\"000030303300314205_06422\", \"000030303300314205_06423\", \"000030303300314205_06444\" ,\"000030494900323685_02127\", \"000030494900323685_02770\", \"000030494900323685_02513\"]\n",
    "selected_patches_path = []\n",
    "for patch in path_patches:\n",
    "    if any(item in str(patch) for item in selected_patches):\n",
    "        selected_patches_path.append(patch)\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=cfg.dataset.mean, std=cfg.dataset.stddev),\n",
    "        transforms.Resize(size=(model.resize_param, model.resize_param))\n",
    "    ])\n",
    "\n",
    "params_instance = {'batch_size': 1,\n",
    "                           'shuffle': False,\n",
    "                           'pin_memory': True,\n",
    "                           'num_workers': 2}\n",
    "\n",
    "instances = Dataset_instance(selected_patches_path, transform=None, preprocess=None)\n",
    "generator = DataLoader(instances, **params_instance)\n",
    "\n",
    "encoder.eval()\n",
    "# do not accumulate gradients (faster)\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for x_q, x_k in generator:\n",
    "\n",
    "        img_q = x_q.squeeze().numpy()\n",
    "        plt.imshow(img_q)\n",
    "        plt.title(\"Patch\")\n",
    "        plt.show()\n",
    "\n",
    "        img_k = x_k.squeeze().numpy()\n",
    "        plt.imshow(img_k)\n",
    "        plt.show()\n",
    "\n",
    "        # x_q, x_k = x_q.to(device, non_blocking=True), x_k.to(device, non_blocking=True)\n",
    "\n",
    "        # q = encoder(x_q) # q : (N, 128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hlung",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
