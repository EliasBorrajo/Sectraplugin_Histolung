{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     ID\n",
      "FILENAME               \n",
      "000030069800299917  000\n",
      "000030069800301408  000\n",
      "000030069800301406  000\n",
      "000033385500476542  001\n",
      "000033340300479660  002\n",
      "...                 ...\n",
      "000032301600414125  223\n",
      "000032301600414861  223\n",
      "000032301600414863  223\n",
      "000032302500414881  223\n",
      "000032301600414865  223\n",
      "\n",
      "[2087 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from natsort import natsorted\n",
    "\n",
    "thispath = Path.cwd().resolve()\n",
    "\n",
    "datadir = Path(thispath.parent / \"data\")\n",
    "reportsdir = Path(datadir / \"csv_folder\" / \"reports\")\n",
    "\n",
    "reports_path = natsorted([i for i in reportsdir.rglob(\"*.xls\") if \"Lung\" in str(i)])\n",
    "\n",
    "dfs = []\n",
    "for report in reports_path:\n",
    "    report = pd.read_excel(report, index_col=0, usecols=[\"FILENAME\", \"NATOIL\"],\n",
    "                           dtype={\"FILENAME\": str, \"NATOIL\": str})\n",
    "    dfs.append(report)\n",
    "    \n",
    "reports = pd.concat(dfs)\n",
    "reports.sort_values(\"NATOIL\", inplace=True)\n",
    "\n",
    "temp = reports.iloc[0][0]\n",
    "id_list = []\n",
    "count = 0\n",
    "for index, row in reports.iterrows():\n",
    "    if row[0] != temp:\n",
    "        count += 1\n",
    "        temp = row[0]\n",
    "    id_list.append(str(count).zfill(3))\n",
    "\n",
    "reports[\"ID\"] = id_list\n",
    "reports.drop(\"NATOIL\", axis=1, inplace=True)\n",
    "print(reports)\n",
    "reports.to_csv(datadir / \"patients_ID.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number WSI TRAIN: 1069, Number WSI VALID: 247\n",
      "Datasplit labels TRAIN: [187 560 194 293], Datasplit labels TEST: [ 45 128  57  46]\n",
      "Number WSI TRAIN: 1038, Number WSI VALID: 278\n",
      "Datasplit labels TRAIN: [184 535 198 270], Datasplit labels TEST: [ 48 153  53  69]\n",
      "Number WSI TRAIN: 1018, Number WSI VALID: 298\n",
      "Datasplit labels TRAIN: [171 545 184 264], Datasplit labels TEST: [ 61 143  67  75]\n",
      "Number WSI TRAIN: 1060, Number WSI VALID: 256\n",
      "Datasplit labels TRAIN: [167 611 182 230], Datasplit labels TEST: [ 65  77  69 109]\n",
      "Number WSI TRAIN: 1079, Number WSI VALID: 237\n",
      "Datasplit labels TRAIN: [219 501 246 299], Datasplit labels TEST: [ 13 187   5  40]\n",
      "5_fold_crossvalidation_data_split.csv in /home/lluis/histo_lung/data\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "datadir = Path(thispath.parent / \"data\")\n",
    "k = 5\n",
    "\n",
    "csv_ids = Path(datadir / \"patients_ID.csv\")\n",
    "csv_dataset_AOEC = Path(datadir / \"labels.csv\")\n",
    "\n",
    "# read data\n",
    "dataset_AOEC = pd.read_csv(csv_dataset_AOEC,\n",
    "                            sep=',', \n",
    "                            index_col=0, \n",
    "                            dtype={\"image_num\":str})\n",
    "\n",
    "patients_id = pd.read_csv(csv_ids,\n",
    "                            sep=',', \n",
    "                            index_col=0, \n",
    "                            dtype={\"FILENAME\": str, \"ID\": str})\n",
    "\n",
    "df = patients_id.drop_duplicates(subset='ID', keep=\"first\")\n",
    "patients = df.values\n",
    "\n",
    "folds = create_folds(patients, k)\n",
    "header = [\"images_train\", \"images_validation\", \"labels_train\", \"labels_validation\"]\n",
    "folds_dataset = pd.DataFrame(columns=header)\n",
    "\n",
    "for i in range(k):\n",
    "    train_patients = folds[:i] + folds[i+1:]\n",
    "    train_patients = [item for sublist in train_patients for item in sublist]\n",
    "    train_patients = [item for sublist in train_patients for item in sublist]\n",
    "    validation_patinets = folds[i]\n",
    "    validation_patinets = [item for sublist in validation_patinets for item in sublist]\n",
    "\n",
    "    train_filenames = patients_id[patients_id['ID'].isin(train_patients)].index\n",
    "    validation_filenames = patients_id[patients_id['ID'].isin(validation_patinets)].index\n",
    "    train = dataset_AOEC[dataset_AOEC.index.isin(train_filenames)]\n",
    "    validation = dataset_AOEC[dataset_AOEC.index.isin(validation_filenames)]\n",
    "\n",
    "    images_train = train.index.to_list()\n",
    "    labels_train = train.values.tolist()\n",
    "    images_validation = validation.index.to_list()\n",
    "    labels_validation = validation.values.tolist()\n",
    "\n",
    "    folds_dataset.loc[i] = [images_train, images_validation, labels_train, labels_validation]\n",
    "\n",
    "    print(f\"Number WSI TRAIN: {len(images_train)}, Number WSI VALID: {len(images_validation)}\")\n",
    "    print(f\"Datasplit labels TRAIN: {np.sum(labels_train, axis=0)}, \"\n",
    "        f\"Datasplit labels TEST: {np.sum(labels_validation, axis=0)}\")\n",
    "\n",
    "folds_dataset.index.name = \"fold\"\n",
    "folds_dataset.to_csv(Path(datadir / f\"{k}_fold_crossvalidation_data_split.csv\"))\n",
    "\n",
    "print(f\"{k}_fold_crossvalidation_data_split.csv in {datadir}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hlung",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
