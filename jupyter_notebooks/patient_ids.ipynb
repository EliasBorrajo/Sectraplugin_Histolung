{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     ID\n",
      "FILENAME               \n",
      "000030069800299917  000\n",
      "000030069800301408  000\n",
      "000030069800301406  000\n",
      "000033385500476542  001\n",
      "000033340300479660  002\n",
      "...                 ...\n",
      "000032301600414125  223\n",
      "000032301600414861  223\n",
      "000032301600414863  223\n",
      "000032302500414881  223\n",
      "000032301600414865  223\n",
      "\n",
      "[2087 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from natsort import natsorted\n",
    "\n",
    "thispath = Path.cwd().resolve()\n",
    "\n",
    "datadir = Path(thispath.parent / \"data\")\n",
    "reportsdir = Path(datadir / \"csv_folder\" / \"reports\")\n",
    "\n",
    "reports_path = natsorted([i for i in reportsdir.rglob(\"*.xls\") if \"Lung\" in str(i)])\n",
    "\n",
    "dfs = []\n",
    "for report in reports_path:\n",
    "    report = pd.read_excel(report, index_col=0, usecols=[\"FILENAME\", \"NATOIL\"],\n",
    "                           dtype={\"FILENAME\": str, \"NATOIL\": str})\n",
    "    dfs.append(report)\n",
    "    \n",
    "reports = pd.concat(dfs)\n",
    "reports.sort_values(\"NATOIL\", inplace=True)\n",
    "\n",
    "temp = reports.iloc[0][0]\n",
    "id_list = []\n",
    "count = 0\n",
    "for index, row in reports.iterrows():\n",
    "    if row[0] != temp:\n",
    "        count += 1\n",
    "        temp = row[0]\n",
    "    id_list.append(str(count).zfill(3))\n",
    "\n",
    "reports[\"ID\"] = id_list\n",
    "reports.drop(\"NATOIL\", axis=1, inplace=True)\n",
    "print(reports)\n",
    "reports.to_csv(datadir / \"patients_ID.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number WSI TRAIN: 1069, Number WSI VALID: 247\n",
      "Datasplit labels TRAIN: [187 560 194 293], Datasplit labels TEST: [ 45 128  57  46]\n",
      "Number WSI TRAIN: 1038, Number WSI VALID: 278\n",
      "Datasplit labels TRAIN: [184 535 198 270], Datasplit labels TEST: [ 48 153  53  69]\n",
      "Number WSI TRAIN: 1018, Number WSI VALID: 298\n",
      "Datasplit labels TRAIN: [171 545 184 264], Datasplit labels TEST: [ 61 143  67  75]\n",
      "Number WSI TRAIN: 1060, Number WSI VALID: 256\n",
      "Datasplit labels TRAIN: [167 611 182 230], Datasplit labels TEST: [ 65  77  69 109]\n",
      "Number WSI TRAIN: 1079, Number WSI VALID: 237\n",
      "Datasplit labels TRAIN: [219 501 246 299], Datasplit labels TEST: [ 13 187   5  40]\n",
      "5_fold_crossvalidation_data_split.csv in /home/lluis/histo_lung/data\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "datadir = Path(thispath.parent / \"data\")\n",
    "k = 5\n",
    "\n",
    "csv_ids = Path(datadir / \"patients_ID.csv\")\n",
    "csv_dataset_AOEC = Path(datadir / \"labels.csv\")\n",
    "\n",
    "# read data\n",
    "dataset_AOEC = pd.read_csv(csv_dataset_AOEC,\n",
    "                            sep=',', \n",
    "                            index_col=0, \n",
    "                            dtype={\"image_num\":str})\n",
    "\n",
    "patients_id = pd.read_csv(csv_ids,\n",
    "                            sep=',', \n",
    "                            index_col=0, \n",
    "                            dtype={\"FILENAME\": str, \"ID\": str})\n",
    "\n",
    "df = patients_id.drop_duplicates(subset='ID', keep=\"first\")\n",
    "patients = df.values\n",
    "\n",
    "folds = create_folds(patients, k)\n",
    "header = [\"images_train\", \"images_validation\", \"labels_train\", \"labels_validation\"]\n",
    "folds_dataset = pd.DataFrame(columns=header)\n",
    "\n",
    "for i in range(k):\n",
    "    train_patients = folds[:i] + folds[i+1:]\n",
    "    train_patients = [item for sublist in train_patients for item in sublist]\n",
    "    train_patients = [item for sublist in train_patients for item in sublist]\n",
    "    validation_patinets = folds[i]\n",
    "    validation_patinets = [item for sublist in validation_patinets for item in sublist]\n",
    "\n",
    "    train_filenames = patients_id[patients_id['ID'].isin(train_patients)].index\n",
    "    validation_filenames = patients_id[patients_id['ID'].isin(validation_patinets)].index\n",
    "    train = dataset_AOEC[dataset_AOEC.index.isin(train_filenames)]\n",
    "    validation = dataset_AOEC[dataset_AOEC.index.isin(validation_filenames)]\n",
    "\n",
    "    images_train = train.index.to_list()\n",
    "    labels_train = train.values.tolist()\n",
    "    images_validation = validation.index.to_list()\n",
    "    labels_validation = validation.values.tolist()\n",
    "\n",
    "    folds_dataset.loc[i] = [images_train, images_validation, labels_train, labels_validation]\n",
    "\n",
    "    print(f\"Number WSI TRAIN: {len(images_train)}, Number WSI VALID: {len(images_validation)}\")\n",
    "    print(f\"Datasplit labels TRAIN: {np.sum(labels_train, axis=0)}, \"\n",
    "        f\"Datasplit labels TEST: {np.sum(labels_validation, axis=0)}\")\n",
    "\n",
    "folds_dataset.index.name = \"fold\"\n",
    "folds_dataset.to_csv(Path(datadir / f\"{k}_fold_crossvalidation_data_split.csv\"))\n",
    "\n",
    "print(f\"{k}_fold_crossvalidation_data_split.csv in {datadir}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as stat\n",
    "\"\"\"\n",
    "Autov2 1296\n",
    "Number WSI TRAIN: 1049, Number WSI VALID: 247\n",
    "Datasplit labels TRAIN: [ 35 602 285 184], Datasplit labels TEST: [ 16 139  85  22]\n",
    "Number WSI TRAIN: 1018, Number WSI VALID: 278\n",
    "Datasplit labels TRAIN: [ 44 581 292 169], Datasplit labels TEST: [  7 160  78  37]\n",
    "Number WSI TRAIN: 1005, Number WSI VALID: 291\n",
    "Datasplit labels TRAIN: [ 33 581 268 165], Datasplit labels TEST: [ 18 160 102  41]\n",
    "Number WSI TRAIN: 1040, Number WSI VALID: 256\n",
    "Datasplit labels TRAIN: [ 48 647 276 126], Datasplit labels TEST: [ 3 94 94 80]\n",
    "Number WSI TRAIN: 1072, Number WSI VALID: 224\n",
    "Datasplit labels TRAIN: [ 44 553 359 180], Datasplit labels TEST: [  7 188  11  26]\n",
    "\n",
    "SCLC train: 40.8 ± 6.457553716385176\n",
    "LUAD train: 592.8 ± 34.94567212116545\n",
    "LUSC train: 296 ± 36.36619309193636\n",
    "NL train: 164.8 ± 23.03692687838376\n",
    "SCLC valid: 10.2 ± 6.457553716385176\n",
    "LUAD valid: 148.2 ± 34.94567212116545\n",
    "LUSC valid: 74 ± 36.36619309193636\n",
    "NL valid: 41.2 ± 23.03692687838376\n",
    "\n",
    "Manual 1226\n",
    "Number WSI TRAIN: 1002, Number WSI VALID: 223\n",
    "Datasplit labels TRAIN: [ 37 493 268 211], Datasplit labels TEST: [ 16 108  85  26]\n",
    "Number WSI TRAIN: 959, Number WSI VALID: 266\n",
    "Datasplit labels TRAIN: [ 46 472 279 180], Datasplit labels TEST: [  7 129  74  57]\n",
    "Number WSI TRAIN: 950, Number WSI VALID: 275\n",
    "Datasplit labels TRAIN: [ 35 470 270 188], Datasplit labels TEST: [ 18 131  83  49]\n",
    "Number WSI TRAIN: 976, Number WSI VALID: 249\n",
    "Datasplit labels TRAIN: [ 48 529 251 167], Datasplit labels TEST: [  5  72 102  70]\n",
    "Number WSI TRAIN: 1013, Number WSI VALID: 212\n",
    "Datasplit labels TRAIN: [ 46 440 344 202], Datasplit labels TEST: [  7 161   9  35]\n",
    "\n",
    "SCLC train: 42.4 ± 5.941380311005179\n",
    "LUAD train: 480.8 ± 32.90440699967103\n",
    "LUSC train: 282.4 ± 35.892896233098824\n",
    "NL train: 189.6 ± 17.444196742756603\n",
    "SCLC valid: 10.6 ± 5.941380311005179\n",
    "LUAD valid: 120.2 ± 32.90440699967103\n",
    "LUSC valid: 70.6 ± 35.892896233098824\n",
    "NL valid: 47.4 ± 17.444196742756603\n",
    "\"\"\"\n",
    "\n",
    "sclc_train = [37, 46, 35, 48, 46]\n",
    "luad_train = [493, 472, 470, 529, 440]\n",
    "lusc_train = [268, 279, 270, 251, 344]\n",
    "nl_train = [211, 180, 188, 167, 202]\n",
    "\n",
    "sclc_valid = [16, 7, 18, 5, 7]\n",
    "luad_valid = [108, 129, 131, 72, 161]\n",
    "lusc_valid = [85, 74, 83, 102, 9]\n",
    "nl_valid = [26, 57, 49, 70, 35]\n",
    "\n",
    "mean_sclc_train = stat.mean(sclc_train)\n",
    "mean_luad_train = stat.mean(luad_train)\n",
    "mean_lusc_train = stat.mean(lusc_train)\n",
    "mean_nl_train = stat.mean(nl_train)\n",
    "\n",
    "std_sclc_train = stat.stdev(sclc_train)\n",
    "std_luad_train = stat.stdev(luad_train)\n",
    "std_lusc_train = stat.stdev(lusc_train)\n",
    "std_nl_train = stat.stdev(nl_train)\n",
    "\n",
    "mean_sclc_valid = stat.mean(sclc_valid)\n",
    "mean_luad_valid = stat.mean(luad_valid)\n",
    "mean_lusc_valid = stat.mean(lusc_valid)\n",
    "mean_nl_valid = stat.mean(nl_valid)\n",
    "\n",
    "std_sclc_valid = stat.stdev(sclc_valid)\n",
    "std_luad_valid = stat.stdev(luad_valid)\n",
    "std_lusc_valid = stat.stdev(lusc_valid)\n",
    "std_nl_valid = stat.stdev(nl_valid)\n",
    "\n",
    "print(f\"SCLC train: {mean_sclc_train} \\u00B1 {std_sclc_train}\")\n",
    "print(f\"LUAD train: {mean_luad_train} \\u00B1 {std_luad_train}\")\n",
    "print(f\"LUSC train: {mean_lusc_train} \\u00B1 {std_lusc_train}\")\n",
    "print(f\"NL train: {mean_nl_train} \\u00B1 {std_nl_train}\")\n",
    "\n",
    "print(f\"SCLC valid: {mean_sclc_valid} \\u00B1 {std_sclc_valid}\")\n",
    "print(f\"LUAD valid: {mean_luad_valid} \\u00B1 {std_luad_valid}\")\n",
    "print(f\"LUSC valid: {mean_lusc_valid} \\u00B1 {std_lusc_valid}\")\n",
    "print(f\"NL valid: {mean_nl_valid} \\u00B1 {std_nl_valid}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hlung",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
